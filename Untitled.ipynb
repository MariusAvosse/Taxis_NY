{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65361999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/29 15:24:10 WARN Utils: Your hostname, marius-Latitude-3410 resolves to a loopback address: 127.0.1.1; using 10.30.204.156 instead (on interface wlp0s20f3)\n",
      "23/05/29 15:24:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/29 15:24:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/29 15:24:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql\n",
    "\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"BIG DATA PROJECT\")\n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geojson geopandas plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a479fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipyleaflet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb14146",
   "metadata": {},
   "source": [
    "## New York taxis trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44717bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.918 192536.086, 933091.011 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((1033269.244 172126.008, 103343...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.770 256767.698, 1026495.593 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.467 203714.076, 992068.667 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.310 144283.336, 936046.565 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1025414.782 270986.139, 1025138.624 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((1011466.966 216463.005, 1011545.889 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((980555.204 196138.486, 980570.792 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((999804.795 224498.527, 999824....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((997493.323 220912.386, 997355.264 22...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \n",
       "0              EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
       "1           Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
       "2            Bronx  POLYGON ((1026308.770 256767.698, 1026495.593 ...  \n",
       "3        Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
       "4    Staten Island  POLYGON ((935843.310 144283.336, 936046.565 14...  \n",
       "..             ...                                                ...  \n",
       "258          Bronx  POLYGON ((1025414.782 270986.139, 1025138.624 ...  \n",
       "259         Queens  POLYGON ((1011466.966 216463.005, 1011545.889 ...  \n",
       "260      Manhattan  POLYGON ((980555.204 196138.486, 980570.792 19...  \n",
       "261      Manhattan  MULTIPOLYGON (((999804.795 224498.527, 999824....  \n",
       "262      Manhattan  POLYGON ((997493.323 220912.386, 997355.264 22...  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the parquet file\n",
    "import geopandas as gpd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "df_yel= spark.read.parquet(\"/home/marius/Téléchargements/yellow_tripdata_2019-03.parquet\")\n",
    "df_fhv= spark.read.parquet(\"/home/marius/Téléchargements/fhv_tripdata_2019-03.parquet\")\n",
    "\n",
    "df_zones = gpd.read_file(\"/home/marius/Téléchargements/taxi_zones/taxi_zones.shp\")\n",
    "\n",
    "\n",
    "df_yel.columns\n",
    "#df_fhv.columns\n",
    "#df_yel.show()\n",
    "#df_fhv.show()\n",
    "\n",
    "df_zones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f42e2",
   "metadata": {},
   "source": [
    "## Using data as parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed25f70",
   "metadata": {},
   "source": [
    "1. What is the number of partitions of the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yellow taxis\n",
    "num_partitions_yel = df_yel.rdd.getNumPartitions()\n",
    "num_partitions_yel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680e9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fhv taxis\n",
    "num_partitions_fhv = df_fhv.rdd.getNumPartitions()\n",
    "num_partitions_fhv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b31d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping na values \n",
    "df_yel.na.drop()\n",
    "df_fhv.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a34b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc9d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yellow taxis\n",
    "df_yel.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3503e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fhv taxis\n",
    "df_fhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d90811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9205b892",
   "metadata": {},
   "source": [
    "## Investigate (at least) one month of data in 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf871092",
   "metadata": {},
   "source": [
    "1. Using these boundaries, filter the 2019 data (using pickup and dropoff longitude and\n",
    "latitude) and count the number of trips for each value of passenger_count and make a\n",
    "plot of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec479a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "  \n",
    "# Return Centroid as crs code of 3310 for calcuating distance in meters.\n",
    "     \n",
    "df_zones[\"centroid\"] = df_zones.geometry.centroid.to_crs(epsg=3310)\n",
    "    \n",
    "# Convert cordinates to the WSG84 lat/long CRS has a EPSG code of 4326.\n",
    "df_zones[\"latitude\"] = df_zones.centroid.to_crs(epsg=4326).y\n",
    "df_zones[\"longitude\"] = df_zones.centroid.to_crs(epsg=4326).x\n",
    "df_zones =df_zones[['LocationID','latitude','longitude','zone','borough']]\n",
    "\n",
    "#convert dataframe zones to spark dataframe \n",
    "df_zones=spark.createDataFrame(df_zones)\n",
    "\n",
    "\n",
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "def renameColumns(df, old_columns, new_columns):\n",
    "    \n",
    "    for old_col, new_col in zip(old_columns,new_columns):\n",
    "        df = df.withColumnRenamed(old_col,new_col)\n",
    "    return df\n",
    "\n",
    "def renameFullColumns(df):\n",
    "    old_columns = ['LocationID','latitude','longitude','zone','borough']\n",
    "    new_columns_pickup = ['DOLocationID', 'pickup_latitude','pickup_longitude',\n",
    "                          'zones_pickup_location','borough_pickup_location']\n",
    "    new_columns_dropoff = ['PULocationID', 'dropoff_latitude','dropoff_longitude',\n",
    "                           'zones_dropoff_location','borough_dropoff_location']\n",
    "    zones_pickup = renameColumns(df, old_columns, new_columns_pickup)\n",
    "    zones_dropoff = renameColumns(df, old_columns, new_columns_dropoff)\n",
    "    return zones_pickup, zones_dropoff\n",
    "\n",
    "# Join trips data with df_zones in order to have longitudes and latitudes\n",
    "def joinDataframes(df,zones_pickup, zones_dropoff):\n",
    "    df=df.join(zones_pickup,['DOLocationID'])\n",
    "    df=df.join(zones_dropoff,['PULocationID'])\n",
    "    return df\n",
    "df_zones.show\n",
    "\n",
    "zones_pickup , zones_dropoff = renameFullColumns(df_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256eac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yellow taxis\n",
    "full_data_yel = joinDataframes(df_yel, zones_pickup, zones_dropoff)\n",
    "full_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9149dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fhv taxis\n",
    "full_data_fhv = joinDataframes(df_fhv, zones_pickup, zones_dropoff)\n",
    "full_data_fhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a306a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filterData(df):\n",
    "    return df[(df['pickup_latitude'] >= 40.58) & \n",
    "                  (df['pickup_latitude'] <= 40.90) & \n",
    "                  (df['dropoff_latitude'] >= 40.58) & \n",
    "                  (df['dropoff_latitude'] <= 40.90) & \n",
    "                  (df['pickup_longitude'] >= -74.10) & \n",
    "                  (df['pickup_longitude'] <= -73.70) & \n",
    "                  (df['dropoff_longitude'] >= -74.10) & \n",
    "                  (df['dropoff_longitude'] <= -73.70)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c42c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for yellow taxis\n",
    "df_yel_filtered = filterData(full_data_yel)\n",
    "df_yel_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fhv taxis\n",
    "df_fhv_filtered = filterData(full_data_fhv)\n",
    "df_fhv_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3eace",
   "metadata": {},
   "source": [
    "count the number of trips for each value of passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ad8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Count the number of trips for each value of passenger_count\n",
    "# for yellow taxis\n",
    "df_passenger=df_yel_filtered.groupby('passenger_count').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab004fc",
   "metadata": {},
   "source": [
    "Plot the trip counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the trip counts\n",
    "df_passenger_pd = df_passenger.toPandas() #transform to pandas dataframe for plot\n",
    "plt.bar(df_passenger_pd[\"passenger_count\"], df_passenger_pd[\"count\"])\n",
    "plt.xlabel(\"Passenger Count\")\n",
    "plt.ylabel(\"Number of Trips\")\n",
    "plt.title(\"Number of Trips by Passenger Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a4554",
   "metadata": {},
   "source": [
    "1. What’s special with trips with zero passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for trips with zero passengers\n",
    "zero_passenger_data = df_yel_filtered.filter(col(\"passenger_count\") == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf23bd2",
   "metadata": {},
   "source": [
    "2. What’s special with trips with more than 6 passengers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_passenger_data = df_yel_filtered.filter(col(\"passenger_count\") > 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9852d",
   "metadata": {},
   "source": [
    "3. What is the largest distance travelled during this month? Is it the first taxi on the moon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = df_yel_filtered.selectExpr(\"MAX(trip_distance) AS max_distance\").collect()[0][\"max_distance\"]\n",
    "print(\"The largest distance travelled during this month is: \" ,max_distance, \"milles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acadbbb3",
   "metadata": {},
   "source": [
    "4. Plot the distribution of the trip_distance (using an histogram for instance) during year 2019. Focus on trips with non-zero trip distance and trip distance less than 30 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for non-zero trip distances less than 30 miles\n",
    "yel_filtered_data = df_yel_filtered.filter((col(\"trip_distance\") > 0) & (col(\"trip_distance\") < 30))\n",
    "\n",
    "# Convert the filtered data to a Pandas DataFrame for plotting\n",
    "yel_filtered_data = yel_filtered_data.select(\"trip_distance\").toPandas()\n",
    "\n",
    "# Plot the distribution of trip distances\n",
    "plt.hist(yel_filtered_data[\"trip_distance\"], bins=30, edgecolor=\"black\")\n",
    "plt.xlabel(\"Trip Distance (miles)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Trip Distances (2019)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1c732",
   "metadata": {},
   "source": [
    "1. Use the explain method or have a look at the Spark UI to analyze the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yel_filtered.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdcb500",
   "metadata": {},
   "source": [
    "2. Compare the Analyzed Logical Plan and Optimized Logical Plan: \n",
    "Analyzed Logical Plan: This plan represents the logical operations after the analysis phase, where Spark resolves references, applies type checking, and performs other logical optimizations. Optimized Logical Plan: This plan represents the logical operations after further optimization, such as predicate pushdown, column pruning, or constant folding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541da4e",
   "metadata": {},
   "source": [
    "3. Compare the Physical Plan with the Optimized Logical Plan: Physical Plan: This plan describes the actual execution strategy that Spark will use to process the query. It includes details about how the data will be read, transformed, and distributed across the worker nodes. 3-2. Keywords and concepts in the Physical Plan that you would not expect in an RDBMS include: Shuffle: This keyword indicates data shuffling, which involves redistributing data across partitions or nodes, often required for operations like joins or aggregations. Exchange: This keyword represents the exchange of data between partitions or nodes. Sort: This keyword indicates sorting operations performed during the query execution. Broadcast: This keyword represents the broadcasting of small data to all worker nodes, typically used in join operations. Code generation: This indicates that Spark generates code dynamically for specific operations to improve performance. In an RDBMS, the physical plan might involve index scans, table scans, join algorithms, and disk-based operations. The specific keywords and concepts may vary depending on the RDBMS implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1116b",
   "metadata": {},
   "source": [
    "4. Tasks in Spark refer to the individual units of work performed on the data. Each task processes a subset of the data and is executed on a single partition of a stage. The number of tasks within each stage may vary depending on the size of the data and the available resources. You can find the number of tasks for each stage in the Spark UI under the \"Stages\" tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4d24e",
   "metadata": {},
   "source": [
    "1. Break down the trip distance distribution for each day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9613ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the day of the week from the pickup datetime\n",
    "df_with_day_of_week = df_yel_filtered.withColumn('pickup_day_of_week', dayofweek('tpep_pickup_datetime'))\n",
    "\n",
    "# Group by day of the week and calculate the distribution of trip distances\n",
    "distance_breakdown = df_with_day_of_week.groupBy('pickup_day_of_week').agg(mean('trip_distance').alias('avg_distance'))\n",
    "\n",
    "# Convert the result to a Pandas DataFrame for plotting\n",
    "distance_breakdown_pd = distance_breakdown.toPandas()\n",
    "\n",
    "# Plot the breakdown of trip distance\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='pickup_day_of_week', y='avg_distance', data=distance_breakdown_pd)\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Trip Distance')\n",
    "plt.title('Breakdown of Trip Distance by Day of Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77979f7",
   "metadata": {},
   "source": [
    "2. Count the number of distinct pickup location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f1e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_pickup_locations = df_yel_filtered.select('PUlocationID').distinct().count()\n",
    "print(\"Number of distinct pickup locations:\", distinct_pickup_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c03cd",
   "metadata": {},
   "source": [
    "3. Compute and display tips and profits as a function of the pickup location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_profits_by_location = df_yel_filtered.groupBy('PUlocationID').agg(sum('tip_amount').alias('total_tips'),\n",
    "                                                          sum('extra').alias('total_profits'))\n",
    "\n",
    "# Display the results\n",
    "tips_profits_by_location.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ab013",
   "metadata": {},
   "source": [
    "## Investigate one month of trips data in 2019, 2020, 2021, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66354ce0",
   "metadata": {},
   "source": [
    "## For year 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25db197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_yel_2020 = spark.read.parquet(\"/home/marius/Téléchargements/yellow_tripdata_2020-08.parquet\")\n",
    "df_fhv_2020 = spark.read.parquet(\"/home/marius/Téléchargements/fhv_tripdata_2020-08.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4398e0",
   "metadata": {},
   "source": [
    "1. What is the number of partitions of the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6466ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for yellow taxis\n",
    "num_partitions_yel_2020 = df_yel_2020.rdd.getNumPartitions()\n",
    "num_partitions_yel_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b78abcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for fhv taxis\n",
    "num_partitions_fhv_2020 = df_fhv_2020.rdd.getNumPartitions()\n",
    "num_partitions_fhv_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c6df9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dispatching_base_num: string, pickup_datetime: timestamp_ntz, dropOff_datetime: timestamp_ntz, PUlocationID: double, DOlocationID: double, SR_Flag: int, Affiliated_base_number: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping na values \n",
    "df_yel_2020.na.drop()\n",
    "df_fhv_2020.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e939d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2020-08-01 00:02:53|  2020-08-01 00:28:54|            1.0|         13.2|       1.0|                 N|         237|          16|           2|       36.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        40.3|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:08:11|  2020-08-01 00:16:28|            1.0|         2.83|       1.0|                 N|         146|         137|           1|       10.5|  0.5|    0.5|       1.5|         0.0|                  0.3|        15.8|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:22:14|  2020-08-01 00:22:20|            1.0|          0.0|       1.0|                 N|         264|         264|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|       null|\n",
      "|       2| 2020-08-01 00:31:35|  2020-08-01 00:36:54|            1.0|         2.34|       1.0|                 N|          79|         141|           1|        8.0|  0.5|    0.5|      2.36|         0.0|                  0.3|       14.16|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:39:18|  2020-08-01 00:42:09|            1.0|         1.32|       1.0|                 N|         141|         263|           1|        5.5|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:22:49|  2020-08-01 00:31:00|            1.0|         0.88|       1.0|                 N|          41|          74|           2|        7.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|                 0.0|       null|\n",
      "|       1| 2020-08-01 00:53:44|  2020-08-01 01:01:50|            0.0|          3.0|       1.0|                 N|         170|         232|           2|       11.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        15.3|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:02:37|  2020-08-01 00:19:45|            1.0|          4.0|       1.0|                 N|         229|         231|           1|       15.0|  0.5|    0.5|      3.76|         0.0|                  0.3|       22.56|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:37:12|  2020-08-01 01:11:50|            2.0|        13.44|       1.0|                 N|         249|          89|           1|       41.5|  0.5|    0.5|      9.06|         0.0|                  0.3|       54.36|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:08:04|  2020-08-01 00:20:40|            3.0|         3.63|       1.0|                 N|         141|         226|           1|       13.0|  0.5|    0.5|       2.0|         0.0|                  0.3|        18.8|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:02:15|  2020-08-01 00:25:12|            1.0|        10.22|       1.0|                 N|         138|         239|           1|       30.5|  0.5|    0.5|      8.08|        6.12|                  0.3|        48.5|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:30:32|  2020-08-01 00:38:51|            1.0|         3.34|       1.0|                 N|         239|         233|           1|       11.5|  0.5|    0.5|       2.0|         0.0|                  0.3|        17.3|                 2.5|       null|\n",
      "|       1| 2020-08-01 00:06:30|  2020-08-01 00:16:35|            1.0|          2.1|       1.0|                 N|         186|          79|           1|        9.5|  3.0|    0.5|      3.95|         0.0|                  0.3|       17.25|                 2.5|       null|\n",
      "|       1| 2020-08-01 00:35:36|  2020-08-01 00:56:16|            1.0|         11.9|       1.0|                 N|          79|          78|           1|       33.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        36.8|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:00:08|  2020-08-01 00:07:20|            2.0|         2.86|       1.0|                 N|         140|         224|           1|       10.0|  0.5|    0.5|      4.14|         0.0|                  0.3|       17.94|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:15:03|  2020-08-01 00:27:06|            2.0|         2.73|       1.0|                 N|           4|         256|           2|       11.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        15.3|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:30:58|  2020-08-01 00:55:16|            2.0|         7.64|       1.0|                 N|         256|         236|           1|       25.0|  0.5|    0.5|       7.2|         0.0|                  0.3|        36.0|                 2.5|       null|\n",
      "|       2| 2020-08-01 00:43:19|  2020-08-01 00:49:35|            5.0|         0.75|       1.0|                 N|         116|         152|           2|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.3|                 0.0|       null|\n",
      "|       2| 2020-08-01 00:50:32|  2020-08-01 00:58:14|            2.0|         2.91|       1.0|                 N|         152|         244|           1|       10.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.8|                 0.0|       null|\n",
      "|       2| 2020-08-01 01:00:22|  2020-08-01 01:11:55|            5.0|         5.45|       1.0|                 N|         244|         151|           1|       17.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        20.8|                 2.5|       null|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for yellow taxis\n",
    "df_yel_2020.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8606a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2020-08-01 00:55:00|2020-08-01 01:06:00|       264.0|       264.0|   null|                B00009|\n",
      "|              B00021|2020-08-01 00:35:49|2020-08-01 00:40:57|        56.0|        56.0|   null|       B00021         |\n",
      "|              B00021|2020-08-01 00:06:56|2020-08-01 00:19:48|        56.0|        56.0|   null|       B00021         |\n",
      "|              B00021|2020-08-01 00:28:52|2020-08-01 00:33:57|        82.0|        82.0|   null|       B00021         |\n",
      "|              B00021|2020-08-01 00:57:53|2020-08-01 01:08:33|        70.0|        70.0|   null|       B00021         |\n",
      "|              B00021|2020-08-01 00:20:12|2020-08-01 00:28:51|       129.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2020-08-01 00:27:21|2020-08-01 00:39:10|       264.0|       188.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:44:15|2020-08-01 00:49:41|       264.0|        71.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:11:05|2020-08-01 00:26:11|       264.0|        71.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:38:58|2020-08-01 00:53:09|       264.0|       133.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:11:46|2020-08-01 00:17:36|       264.0|        76.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:26:01|2020-08-01 00:35:10|       264.0|        61.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:45:45|2020-08-01 00:56:31|       264.0|        76.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:48:59|2020-08-01 01:00:07|       264.0|        89.0|   null|                B00037|\n",
      "|              B00037|2020-08-01 00:02:34|2020-08-01 00:16:05|       264.0|        91.0|   null|                B00037|\n",
      "|              B00112|2020-08-01 00:27:10|2020-08-01 01:01:33|       264.0|       185.0|   null|                B00112|\n",
      "|              B00112|2020-08-01 00:13:29|2020-08-01 00:45:41|       264.0|        35.0|   null|                B00112|\n",
      "|              B00149|2020-08-01 00:27:29|2020-08-01 00:54:56|       264.0|       198.0|   null|                B00149|\n",
      "|              B00149|2020-08-01 00:13:06|2020-08-01 00:26:39|       264.0|        76.0|   null|                B00149|\n",
      "|              B00149|2020-08-01 00:33:53|2020-08-01 00:55:45|       264.0|        61.0|   null|                B00149|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for fhv taxis\n",
    "df_fhv_2020.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec60150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bed59a2",
   "metadata": {},
   "source": [
    "## Assessing seasonalities and looking at time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db9fc3",
   "metadata": {},
   "source": [
    "1. The number of pickups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88561b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_pickup = df_yel_filtered.groupby(dayofweek('tpep_pickup_datetime').alias('pickup_day'),\n",
    "                             hour('tpep_pickup_datetime').alias('pickup_hour')).count()\n",
    "#display the result\n",
    "#print(\"The number of pickups is: \", counts_pickup.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355c23fd",
   "metadata": {},
   "source": [
    "2. The average fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e41035",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fare = df_yel_filtered.groupby(dayofweek('tpep_pickup_datetime').alias('pickup_day'),\n",
    "                        hour('tpep_pickup_datetime').alias('pickup_hour')).avg('fare_amount')\n",
    "#display the result\n",
    "#print(\"The average fare is: \" ,avg_fare)\n",
    "avg_fare=avg_fare.toPandas()\n",
    "avg_fare=avg_fare.sort_values(by=['pickup_hour'])\n",
    "avg_fare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc8e1b",
   "metadata": {},
   "source": [
    "3. The average trip duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trip_duration = df_yel_filtered.groupby(dayofweek('tpep_pickup_datetime').alias('pickup_day'), \n",
    "                            hour('tpep_pickup_datetime').alias('pickup_hour')).avg('trip_distance')\n",
    "#display the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b41cc",
   "metadata": {},
   "source": [
    "4. Plot the average of ongoing trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into pandas dataframe\n",
    "df_yel_filtered = df_yel_filtered.toPandas()\n",
    "\n",
    "# Convert the 'tpep_dropoff_datetime' and 'tpep_pickup_datetime' columns to datetime format\n",
    "df_yel_filtered['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df_yel_filtered['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Calculate the duration of each trip by subtracting the pickup datetime \n",
    "# from the dropoff datetime to get the trip duration in seconds.\n",
    "\n",
    "df_yel_filtered['trip_duration'] = (df_yel_filtered['tpep_dropoff_datetime'] - \n",
    "                                    df_yel_filtered['tpep_pickup_datetime']).dt.total_seconds()\n",
    "\n",
    "# Group the data by the desired time interval and calculate the average trip duration for each interval.\n",
    "\n",
    "average_trip_duration = df_yel_filtered.groupby(df_yel_filtered['tpep_pickup_datetime'].dt.hour)['trip_duration'].mean()\n",
    "\n",
    "# the plot\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.bar(average_trip_duration.index, average_trip_duration.values)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Trip Duration (seconds)')\n",
    "plt.title('Average Trip Duration by Hour')\n",
    "plt.xticks(average_trip_duration.index)\n",
    "plt.grid(True) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f0576",
   "metadata": {},
   "source": [
    "## Rides to the airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea137dd2",
   "metadata": {},
   "source": [
    "1. Median duration of taxi trip leaving Midtown (Southern Manhattan) headed for JFK Airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9012a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "midtown = {'longitude_min': -74.01, 'longitude_max': -73.96, 'latitude_min': 40.73, 'latitude_max': 40.78}\n",
    "jfk = {'longitude_min': -73.85, 'longitude_max': -73.74, 'latitude_min': 40.62, 'latitude_max': 40.66}\n",
    "newark = {'longitude_min': -74.20, 'longitude_max': -74.14, 'latitude_min': 40.65, 'latitude_max': 40.73}\n",
    "laguardia = {'longitude_min': -73.89, 'longitude_max': -73.85, 'latitude_min': 40.77, 'latitude_max': 40.80}\n",
    " \n",
    "\n",
    "median_trip_duration = df_yel_filtered(col(\"pickup_longitude\") >= )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e0271",
   "metadata": {},
   "source": [
    "## Geographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2645429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GeoJSON file\n",
    "data_geojson = gpd.read_file(\"/home/marius/Téléchargements/map.geojson\")         # Load the GeoJSON file as a GeoDataFrame\n",
    "\n",
    "print(data_geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dac153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register DataFrame as a temporary view for Spark SQL operations\n",
    "#df_yel_filtered.createOrReplaceTempView(\"trips\")\n",
    "\n",
    "# Build a heatmap of number of pickups, number of dropoffs, and number of pickups with dropoff at airports\n",
    "heatmap_pickups = df_yel_filtered.groupBy(\"zones_pickup_location\").count()\n",
    "heatmap_dropoffs = df_yel_filtered.groupBy(\"zones_dropoff_location\").count()\n",
    "heatmap_airport_pickups = df_yel_filtered.filter(col(\"zones_dropoff_location\").isin(['JFK', \n",
    "                                        'LaGuardia', 'Newark'])).groupBy(\"zones_pickup_location\").count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a choropleth map of number of pickups in the area, ratio of card payments to cash payments, and ratio of total fare to trip duration\n",
    "choropleth_pickups = df_yel_filtered.groupBy(\"zones_pickup_location\").count()\n",
    "choropleth_payment_ratio = df_yel_filtered.groupBy(\"zones_pickup_location\").agg(\n",
    "    (sum(when(col(\"payment_type\") == 1, 1).otherwise(0)) /\n",
    "     sum(when(col(\"payment_type\") == 2, 1).otherwise(0))).alias(\"payment_ratio\")\n",
    ")\n",
    "choropleth_fare_duration_ratio = df_yel_filtered.groupBy(\"zones_dropoff_location\").agg(\n",
    "    (sum(\"total_amount\") / sum(\"trip_distance\")).alias(\"fare_duration_ratio\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed98971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9096279a",
   "metadata": {},
   "source": [
    "## Covid impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36529769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
